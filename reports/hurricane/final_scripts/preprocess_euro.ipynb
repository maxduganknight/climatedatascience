{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfolium\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cdsapi \n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io import shapereader\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import folium\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from numpy.polynomial.polynomial import Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "# functions for state masking\n",
    "\n",
    "def get_shape_us(shapefile, state_abbreviation):\n",
    "    shapefile = shapefile.to_crs(\"EPSG:4326\")\n",
    "    state_shape = shapefile[shapefile.STUSPS == state_abbreviation].geometry\n",
    "    return state_shape\n",
    "\n",
    "def mask_xr_dataset(xr_data, shape):\n",
    "    xr_data = xr_data.assign_coords(longitude=(((xr_data.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "    xr_data.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    xr_data_masked = xr_data.rio.clip(shape.geometry.apply(mapping), shape.crs)\n",
    "    return xr_data_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.polynomial import Polynomial\n",
    "\n",
    "# function to add trend line\n",
    "\n",
    "def fit_polynomial(df):\n",
    "    # add trend line\n",
    "    p = Polynomial.fit(df.index, df['extreme_frequency'], 1)\n",
    "    print('Slope: ', p.convert().coef[1])\n",
    "    x_values = np.linspace(df.index.min(), df.index.max(), len(df.index))\n",
    "    y_values = p(x_values)\n",
    "    df['trend'] = y_values\n",
    "    df = df[['year', 'extreme_frequency', 'trend']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 10GB\n",
      "Dimensions:     (valid_time: 253896, latitude: 88, longitude: 113, time: 1)\n",
      "Coordinates:\n",
      "    number      int64 8B 0\n",
      "  * valid_time  (valid_time) datetime64[ns] 2MB 1994-01-01 ... 2024-12-31T23:...\n",
      "  * latitude    (latitude) float64 704B 58.35 58.1 57.85 ... 37.1 36.85 36.6\n",
      "  * longitude   (longitude) float64 904B -11.8 -11.55 -11.3 ... 15.7 15.95 16.2\n",
      "    expver      (valid_time) <U4 4MB dask.array<chunksize=(8184,), meta=np.ndarray>\n",
      "  * time        (time) datetime64[ns] 8B 2013-11-29\n",
      "Data variables:\n",
      "    tp          (valid_time, latitude, longitude, time) float32 10GB dask.array<chunksize=(2728, 30, 38, 1), meta=np.ndarray>\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-01-21T21:48 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# MDK Final Frequency Data preprocessing\n",
    "################################################\n",
    "\n",
    "ERA5 = xr.open_mfdataset('../../../data/UNSEEN/hurricane/europe/ERA5_hourly_Jan_21_update/ERA5_????.nc', combine='by_coords')\n",
    "LSMask = xr.open_dataset('../../../data/UNSEEN/hurricane/lsm_1279l4_0.1x0.1.grb_v4_unpack.nc')\n",
    "# print(\"ERA5 Coordinates:\")\n",
    "# print(ERA5.coords)\n",
    "\n",
    "# print(\"LSMask Coordinates:\")\n",
    "# print(LSMask.coords)\n",
    "\n",
    "# LSMask_interp = LSMask.interp(latitude=ERA5.latitude, longitude=ERA5.longitude, method='nearest')\n",
    "\n",
    "# # Apply the mask to the ERA5 data\n",
    "# ERA5_land = ERA5.where(LSMask_interp.lsm > 0.5)\n",
    "\n",
    "# # Print the resulting dataset\n",
    "# print(ERA5['tp'].values)\n",
    "# print(ERA5_land['tp'].values)\n",
    "\n",
    "LSMask['longitude'] = (((LSMask['longitude'] + 180) % 360) - 180)\n",
    "LSMask_interp = LSMask.interp(latitude=ERA5.latitude, longitude=ERA5.longitude, method='nearest')\n",
    "\n",
    "ERA5_land = (ERA5.where(LSMask_interp.lsm > 0.5))\n",
    "print(ERA5_land)\n",
    "# # Check the unique values in the interpolated LSMask\n",
    "# unique_lsm_values = np.unique(LSMask_interp['lsm'].values)\n",
    "# print(\"Unique values in the interpolated LSMask:\", unique_lsm_values)\n",
    "\n",
    "# # Check the unique values in the masked ERA5 data\n",
    "# unique_era5_land_values = np.unique(ERA5_land['tp'].values)\n",
    "# print(\"Unique values in the masked ERA5 data:\", unique_era5_land_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_weights = np.cos(np.deg2rad(ERA5_land.latitude))\n",
    "area_weights = area_weights.expand_dims({'longitude': ERA5_land.longitude})\n",
    "\n",
    "ERA5_land['tp'] = ERA5_land['tp'] * area_weights\n",
    "\n",
    "ERA5_coarsened = ERA5_land.coarsen(latitude=3, longitude=3, boundary='trim').sum()\n",
    "ERA5_agg = ERA5_coarsened.resample(time='1D').sum()\n",
    "\n",
    "# ERA5_agg_df = ERA5_agg.to_dataframe().reset_index()\n",
    "# ERA5_agg_df = ERA5_agg_df.loc[ERA5_agg_df['time'].dt.month.between(6, 10)]\n",
    "# ERA5_agg_df = ERA5_agg_df[['time', 'tp']]\n",
    "# ERA5_agg_df.to_csv('../../../data/UNSEEN/hurricane/europe/ERA5_1d_raw.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'tp' (time: 1, valid_time: 31)> Size: 248B\n",
      "dask.array<sum-aggregate, shape=(1, 31), dtype=int64, chunksize=(1, 1), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "    number      int64 8B 0\n",
      "  * time        (time) datetime64[ns] 8B 2013-11-29\n",
      "    quantile    float64 8B 0.999\n",
      "  * valid_time  (valid_time) datetime64[ns] 248B 1994-12-31 ... 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data preprocessing for data viz of 999th percentile count data\n",
    "\n",
    "ERA5_agg = ERA5_agg.chunk({'valid_time': -1})\n",
    "extreme_precipitation_threshold = ERA5_agg.sel(valid_time=slice('2000', '2010')).tp.quantile(.999, dim='valid_time')\n",
    "count_above_threshold = xr.where(ERA5_agg['tp'] > extreme_precipitation_threshold, 1, 0)\n",
    "ERA5_agg_annual = count_above_threshold.resample(valid_time='YE').sum()\n",
    "ERA5_agg_annual_total = ERA5_agg_annual.sum(dim=['latitude', 'longitude'])\n",
    "print(ERA5_agg_annual_total)\n",
    "ERA5_extreme_frequency_df = ERA5_agg_annual_total.to_dataframe(name='extreme_frequency').reset_index()\n",
    "ERA5_extreme_frequency_df['year'] = ERA5_extreme_frequency_df['valid_time'].dt.year\n",
    "# plot_df = fit_polynomial(ERA5_extreme_frequency_df)\n",
    "ERA5_extreme_frequency_df.to_csv('../../../data/UNSEEN/hurricane/europe/ERA5_999_counts_all_months.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m ERA5_agg_annual_total \u001b[38;5;241m=\u001b[39m ERA5_agg_annual\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Ensure the DataArray is reduced to a single dimension and compute the result\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m ERA5_agg_annual_total \u001b[38;5;241m=\u001b[39m \u001b[43mERA5_agg_annual_total\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print the resulting DataArray\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(ERA5_agg_annual_total)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/xarray/core/dataarray.py:1178\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/xarray/core/dataarray.py:1146\u001b[0m, in \u001b[0;36mDataArray.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable \u001b[38;5;241m=\u001b[39m new\u001b[38;5;241m.\u001b[39m_variable\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/xarray/core/dataset.py:862\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    859\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    861\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data):\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/xarray/namedarray/daskmanager.py:86\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/xarray/core/variable.py:1920\u001b[0m, in \u001b[0;36mVariable.quantile.<locals>._wrapper\u001b[0;34m(npa, **kwargs)\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper\u001b[39m(npa, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# move quantile axis to end. required for apply_ufunc\u001b[39;00m\n\u001b[0;32m-> 1920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmoveaxis(\u001b[43m_quantile_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/xarray/core/nputils.py:234\u001b[0m, in \u001b[0;36m_create_method.<locals>.f\u001b[0;34m(values, axis, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m     result \u001b[38;5;241m=\u001b[39m bn_func(values, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnpmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1545\u001b[0m, in \u001b[0;36mnanquantile\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_base\u001b[38;5;241m.\u001b[39m_quantile_is_valid(q):\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantiles must be in the range [0, 1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nanquantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1562\u001b[0m, in \u001b[0;36m_nanquantile_unchecked\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;66;03m# apply_along_axis in _nanpercentile doesn't handle empty arrays well,\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;66;03m# so deal them upfront\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_base\u001b[38;5;241m.\u001b[39m_ureduce(a,\n\u001b[1;32m   1564\u001b[0m                               func\u001b[38;5;241m=\u001b[39m_nanquantile_ureduce_func,\n\u001b[1;32m   1565\u001b[0m                               q\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1569\u001b[0m                               overwrite_input\u001b[38;5;241m=\u001b[39moverwrite_input,\n\u001b[1;32m   1570\u001b[0m                               method\u001b[38;5;241m=\u001b[39mmethod)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/numpy/lib/nanfunctions.py:1044\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(out\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf a is inexact, then out must be inexact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1044\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m             \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m tot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(arr, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[1;32m   1047\u001b[0m              where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[1;32m   1048\u001b[0m avg \u001b[38;5;241m=\u001b[39m _divide_by_count(tot, cnt, out\u001b[38;5;241m=\u001b[39mout)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Assuming ERA5_agg is already defined and loaded\n",
    "\n",
    "# Chunk the data\n",
    "ERA5_agg = ERA5_agg.chunk({'time': -1})\n",
    "\n",
    "# Calculate the extreme precipitation threshold\n",
    "extreme_precipitation_threshold = ERA5_agg.sel(time=slice('2000', '2010')).tp.quantile(.999, dim='time')\n",
    "\n",
    "# Count occurrences above the threshold\n",
    "count_above_threshold = xr.where(ERA5_agg['tp'] > extreme_precipitation_threshold, 1, 0)\n",
    "\n",
    "# Resample to annual counts\n",
    "ERA5_agg_annual = count_above_threshold.resample(time='YE').sum()\n",
    "\n",
    "# Sum over latitude and longitude to get total annual counts\n",
    "ERA5_agg_annual_total = ERA5_agg_annual.sum(dim=['latitude', 'longitude'])\n",
    "\n",
    "# Ensure the DataArray is reduced to a single dimension and compute the result\n",
    "ERA5_agg_annual_total = ERA5_agg_annual_total.compute()\n",
    "\n",
    "# Print the resulting DataArray\n",
    "print(ERA5_agg_annual_total)\n",
    "\n",
    "# Convert to DataFrame\n",
    "ERA5_extreme_frequency_df = ERA5_agg_annual_total.to_dataframe(name='extreme_frequency').reset_index()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(ERA5_extreme_frequency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  tp\n",
      "0  1981   0\n",
      "1  1982   1\n",
      "2  1983   0\n",
      "3  1984   3\n",
      "4  1985   6\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing for state level frequency analysis for damages\n",
    "\n",
    "state_abbr = 'MS'\n",
    "\n",
    "def count_extreme_rainfall_events(xr_data, percentile):\n",
    "    era5_5d = xr_data.resample(time='1D').sum()\n",
    "    era5_5d = era5_5d.chunk({'time': -1})\n",
    "    extreme_precipitation_treshold = era5_5d.sel(time=slice(None, '2000')).tp.quantile(percentile, dim=['time'])\n",
    "    count_above_threshold = xr.where(era5_5d['tp'] > extreme_precipitation_treshold, 1, 0)\n",
    "    count_above_threshold = count_above_threshold.sel(time=count_above_threshold['time'].dt.month.isin([6, 7, 8, 9, 10]))\n",
    "    count_above_threshold_df = count_above_threshold.to_dataframe().reset_index()\n",
    "    return count_above_threshold_df\n",
    "\n",
    "ERA5 = xr.open_mfdataset('../../../data/UNSEEN/hurricane/ERA5_hourly/ERA5_????.nc', combine='by_coords')\n",
    "# lat_era5 = ERA5.latitude.values\n",
    "# lon_era5 = ERA5.longitude.values\n",
    "\n",
    "# LSMask = xr.open_dataset('../../../data/UNSEEN/hurricane/ERA5_land_sea_mask_new.nc')\n",
    "# LSMask['longitude'] = (((LSMask['longitude'] + 180) % 360) - 180)\n",
    "# LSMask_interp = LSMask.interp(latitude=lat_era5, longitude=lon_era5)\n",
    "\n",
    "# uncomment below lines to filter for a specific state\n",
    "\n",
    "us_shapefile = gpd.read_file('../../../data/shapefiles/us/tl_2023_us_state.shp')\n",
    "shape = get_shape_us(us_shapefile, state_abbr)\n",
    "filtered_era5 = mask_xr_dataset(ERA5, shape)\n",
    "\n",
    "# ERA5_land = (\n",
    "#     ERA5.where(LSMask_interp['lsm'].sel(time = '1981').squeeze('time') > 0.5)\n",
    "# )\n",
    "\n",
    "# area_weights = np.cos(np.deg2rad(filtered_era5.latitude))\n",
    "# area_weights = area_weights.expand_dims({'longitude': filtered_era5.longitude})\n",
    "\n",
    "#filtered_era5['tp'] = filtered_era5['tp'] * area_weights\n",
    "\n",
    "ERA5_coarsened = filtered_era5.coarsen(latitude=3, longitude=3, boundary='trim').sum()\n",
    "ERA5_extreme_count = count_extreme_rainfall_events(ERA5_coarsened, 0.999)\n",
    "ERA5_extreme_count['year'] = ERA5_extreme_count['time'].dt.year\n",
    "ERA5_extreme_count_grouped = ERA5_extreme_count.groupby('year')['tp'].sum().reset_index(name='tp')\n",
    "print(ERA5_extreme_count_grouped.head())\n",
    "ERA5_extreme_count_grouped.to_csv(f'../../../data/UNSEEN/hurricane/rainfall_preprocessed/states/ERA5_999_counts_{state_abbr}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cds",
   "language": "python",
   "name": "cds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
